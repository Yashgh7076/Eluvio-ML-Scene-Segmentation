# -*- coding: utf-8 -*-
"""model_predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uxMYgWc0X9FWJnNBr16TCcAQ5TKc_3ia
"""

#!pip install focal-loss
import pickle
import torch
import numpy as np
import sklearn
import os
from sklearn import preprocessing
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Suppress TF info
import tensorflow as tf
import matplotlib.pyplot as plt
#from focal_loss import BinaryFocalLoss
import time

#get all files in the folder
directory = 'drive/MyDrive/Eluvio-MLChallenge/data'
files = os.listdir(directory) 
total_files = len(files) #Calculate total number of files 
print(total_files)

window = 7 # Window needs to be an int greater than 1 and odd!
first = int((window - 1)/2)

model1 = tf.keras.models.load_model('drive/MyDrive/Eluvio-MLChallenge/3d_data/sigmoid_final_2.h5') # Naming mistake -> should be softmax
model2 = tf.keras.models.load_model('drive/MyDrive/Eluvio-MLChallenge/3d_data/sigmoid_final_1.h5')

for i in range(12, total_files):
    
    filename = directory + '/' + files[i]
    f = open(filename, 'rb')
    data = pickle.load(f)
    f.close()
        
    feat1 = data['place']
    feat1 = feat1.data.numpy() #convert tensors into numpy arrays for sklearn
    feat1_size = feat1.shape[1]
    
    feat2 = data['cast']
    feat2 = feat2.data.numpy()
    feat2_size = feat2.shape[1]
    
    feat3 = data['action']
    feat3 = feat3.data.numpy()
    feat3_size = feat3.shape[1]
    
    feat4 = data['audio']
    feat4 = feat4.data.numpy()
    feat4_size = feat4.shape[1]
    
    x = np.hstack((feat1, feat2, feat3, feat4))
    #y = data['scene_transition_boundary_ground_truth']
    #y_new = y.data.numpy()
            
    scaler = preprocessing.MinMaxScaler().fit(x)
    x_scaled = scaler.transform(x)
 
    # Pad the start and end with zeros 
    padding = np.zeros((first, x_scaled.shape[1]))
    x_scaled = np.concatenate((padding, x_scaled, padding), axis=0)
                
    #Fold the data set to obtain features from adjoining shots
    N = x_scaled.shape[0] #changed from x_scaled
    j = 0
    #GT = []
    start_s = time.time()

    for p in range(first, (N - first) - 1):
        #window_range = np.arange(start = p - first, stop = p + first + 1)
        temp1 = x_scaled[p - first: p + first + 1, :]
        #print(p - first, p + first + 1, p - first, temp1.shape[0], temp1.shape[1])
        temp1 = np.reshape(temp1, (1, window, temp1.shape[1]))
        
        #temp2 = y[p - first].data.numpy()
        #print(p -first)
        #temp2 = str(temp2)
        if(j == 0):
            X = temp1
        else:
            X = np.concatenate((X, temp1), axis=0)

        #GT.append(temp2)
        j = j + 1    

    end_s = time.time()
    
    if(i < 37):
      predictions = model1.predict(X)
      print(i, 1)
    else:
      predictions = model2.predict(X)
      print(i, 2)

    print('Iter ID:',i,' ','Time needed in s', end_s - start_s,' ','Array sizes, X:', X.shape, 'Predictions:', predictions.shape)

    # Code for printing the output to text file
    #predictions_out = 'drive/MyDrive/Eluvio-MLChallenge' + '/' + data['imdb_id'] + '.txt'
    #print(predictions_out)
    #for p in range(predictions.shape[0]):
    #  print(predictions[p, :])
    #np.savetxt(predictions_out, predictions[:,1])

    # Generate pickle files to store predictions
    a = data['scene_transition_boundary_ground_truth']
    a = a.data.numpy()

    c = data['shot_end_frame']
    c = c.data.numpy()

    d = data['imdb_id']

    new_dict = dict([('scene_transition_boundary_ground_truth',a), ('scene_transition_boundary_prediction',predictions[:,1]), ('shot_end_frame',c), ('imdb_id',d)])
    
    # use this routine to write final output pickle file
    new_filename = 'drive/MyDrive/Eluvio-MLChallenge/output_softmax' + '/' + d + '.pkl'
    print(new_filename)
    with open(new_filename, 'wb') as handle:
        pickle.dump(new_dict, handle)